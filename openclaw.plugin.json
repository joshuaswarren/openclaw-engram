{
  "id": "openclaw-engram",
  "kind": "memory",
  "configSchema": {
    "type": "object",
    "additionalProperties": false,
    "properties": {
      "openaiApiKey": {
        "type": "string",
        "description": "OpenAI API key (or set OPENAI_API_KEY env var)"
      },
      "model": {
        "type": "string",
        "default": "gpt-5.2",
        "description": "OpenAI model for extraction/consolidation"
      },
      "reasoningEffort": {
        "type": "string",
        "enum": ["none", "low", "medium", "high"],
        "default": "low",
        "description": "Reasoning effort for extraction"
      },
      "triggerMode": {
        "type": "string",
        "enum": ["smart", "every_n", "time_based"],
        "default": "smart",
        "description": "Buffer trigger mode"
      },
      "bufferMaxTurns": {
        "type": "number",
        "default": 5,
        "description": "Max turns before forced extraction"
      },
      "bufferMaxMinutes": {
        "type": "number",
        "default": 15,
        "description": "Max minutes before forced extraction"
      },
      "consolidateEveryN": {
        "type": "number",
        "default": 3,
        "description": "Run consolidation every N extractions"
      },
      "highSignalPatterns": {
        "type": "array",
        "items": { "type": "string" },
        "description": "Custom regex patterns for immediate extraction"
      },
      "maxMemoryTokens": {
        "type": "number",
        "default": 2000,
        "description": "Max tokens injected per turn"
      },
      "qmdEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Use QMD for search"
      },
      "qmdCollection": {
        "type": "string",
        "default": "openclaw-engram",
        "description": "QMD collection name"
      },
      "qmdMaxResults": {
        "type": "number",
        "default": 8,
        "description": "Max QMD results per search"
      },
      "memoryDir": {
        "type": "string",
        "description": "Override memory storage directory"
      },
      "debug": {
        "type": "boolean",
        "default": false,
        "description": "Enable debug logging"
      },
      "identityEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable agent identity reflections (appends to workspace IDENTITY.md)"
      },
      "injectQuestions": {
        "type": "boolean",
        "default": false,
        "description": "Inject the most relevant open question into the system prompt"
      },
      "commitmentDecayDays": {
        "type": "number",
        "default": 90,
        "description": "Days before fulfilled/expired commitments are removed"
      },
      "workspaceDir": {
        "type": "string",
        "description": "Override workspace directory path"
      },
      "accessTrackingEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Track memory access counts and recency"
      },
      "accessTrackingBufferMaxSize": {
        "type": "number",
        "default": 100,
        "description": "Max entries in access tracking buffer before flush"
      },
      "recencyWeight": {
        "type": "number",
        "default": 0.2,
        "description": "Weight for recency boosting in search (0-1)"
      },
      "boostAccessCount": {
        "type": "boolean",
        "default": true,
        "description": "Boost frequently accessed memories in search results"
      },
      "queryExpansionEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable heuristic query expansion for retrieval (no LLM calls)."
      },
      "queryExpansionMaxQueries": {
        "type": "number",
        "default": 4,
        "description": "Max expanded queries to run (including the original prompt)."
      },
      "queryExpansionMinTokenLen": {
        "type": "number",
        "default": 3,
        "description": "Minimum token length to include in heuristic query expansion."
      },
      "rerankEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable LLM re-ranking of retrieved memories. Default off."
      },
      "rerankProvider": {
        "type": "string",
        "default": "local",
        "description": "Re-ranking provider: 'local' uses local LLM only. 'cloud' is reserved/experimental (currently treated as no-op).",
        "enum": ["local", "cloud"]
      },
      "rerankMaxCandidates": {
        "type": "number",
        "default": 20,
        "description": "Max candidates to send to the re-ranker."
      },
      "rerankTimeoutMs": {
        "type": "number",
        "default": 8000,
        "description": "Timeout for re-ranking requests (ms). Fail-open on timeout."
      },
      "rerankCacheEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Cache re-ranking results in-memory for repeated queries."
      },
      "rerankCacheTtlMs": {
        "type": "number",
        "default": 3600000,
        "description": "TTL for in-memory re-ranking cache (ms)."
      },
      "feedbackEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable feedback capture tool for memory relevance (thumbs up/down)."
      },
      "negativeExamplesEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable negative examples (track retrieved-but-not-useful memories) and apply a small ranking penalty."
      },
      "negativeExamplesPenaltyPerHit": {
        "type": "number",
        "default": 0.05,
        "description": "Ranking penalty per negative example hit (keep small; QMD scores are ~0-1)."
      },
      "negativeExamplesPenaltyCap": {
        "type": "number",
        "default": 0.25,
        "description": "Maximum ranking penalty applied from negative examples."
      },
      "chunkingEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable automatic chunking of long memories"
      },
      "chunkingTargetTokens": {
        "type": "number",
        "default": 200,
        "description": "Target tokens per chunk"
      },
      "chunkingMinTokens": {
        "type": "number",
        "default": 150,
        "description": "Minimum tokens to trigger chunking"
      },
      "chunkingOverlapSentences": {
        "type": "number",
        "default": 2,
        "description": "Number of sentences to overlap between chunks"
      },
      "contradictionDetectionEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable automatic contradiction detection with LLM verification"
      },
      "contradictionSimilarityThreshold": {
        "type": "number",
        "default": 0.7,
        "description": "QMD similarity threshold to trigger contradiction check"
      },
      "contradictionMinConfidence": {
        "type": "number",
        "default": 0.9,
        "description": "Minimum LLM confidence to auto-resolve contradictions"
      },
      "contradictionAutoResolve": {
        "type": "boolean",
        "default": true,
        "description": "Automatically supersede contradicted memories"
      },
      "memoryLinkingEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable automatic memory linking to build knowledge graph"
      },
      "threadingEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable conversation threading"
      },
      "threadingGapMinutes": {
        "type": "number",
        "default": 30,
        "description": "Minutes of gap to start a new thread"
      },
      "summarizationEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable automatic memory summarization/compression"
      },
      "summarizationTriggerCount": {
        "type": "number",
        "default": 1000,
        "description": "Memory count threshold to trigger summarization"
      },
      "summarizationRecentToKeep": {
        "type": "number",
        "default": 300,
        "description": "Number of recent memories to keep uncompressed"
      },
      "summarizationImportanceThreshold": {
        "type": "number",
        "default": 0.3,
        "description": "Only compress memories with importance below this threshold"
      },
      "summarizationProtectedTags": {
        "type": "array",
        "items": { "type": "string" },
        "default": ["commitment", "preference", "decision", "principle"],
        "description": "Tags that protect memories from compression"
      },
      "topicExtractionEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable topic extraction during consolidation"
      },
      "topicExtractionTopN": {
        "type": "number",
        "default": 50,
        "description": "Number of top topics to extract"
      },
      "transcriptEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable transcript archiving"
      },
      "transcriptRetentionDays": {
        "type": "number",
        "default": 7,
        "description": "Days to retain transcript entries"
      },
      "transcriptSkipChannelTypes": {
        "type": "array",
        "items": { "type": "string" },
        "default": ["cron"],
        "description": "Channel types to skip from transcript logging (e.g., cron)"
      },
      "transcriptRecallHours": {
        "type": "number",
        "default": 12,
        "description": "Hours of transcript history to recall"
      },
      "maxTranscriptTurns": {
        "type": "number",
        "default": 50,
        "description": "Maximum transcript turns to inject"
      },
      "maxTranscriptTokens": {
        "type": "number",
        "default": 1000,
        "description": "Maximum tokens for transcript injection"
      },
      "checkpointEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable conversation checkpoints"
      },
      "checkpointTurns": {
        "type": "number",
        "default": 15,
        "description": "Number of turns per checkpoint"
      },
      "hourlySummariesEnabled": {
        "type": "boolean",
        "default": true,
        "description": "Enable hourly conversation summaries"
      },
      "summaryRecallHours": {
        "type": "number",
        "default": 24,
        "description": "Hours of summary history to recall"
      },
      "maxSummaryCount": {
        "type": "number",
        "default": 6,
        "description": "Maximum number of summaries to inject"
      },
      "summaryModel": {
        "type": "string",
        "description": "Model for hourly summaries (defaults to main model)"
      },
      "localLlmEnabled": {
        "type": "boolean",
        "default": false,
        "description": "Enable local LLM for extraction and summarization (e.g., LM Studio, Ollama)"
      },
      "localLlmUrl": {
        "type": "string",
        "default": "http://localhost:1234/v1",
        "description": "URL for local LLM OpenAI-compatible endpoint"
      },
      "localLlmModel": {
        "type": "string",
        "default": "local-model",
        "description": "Model name for local LLM requests"
      },
      "localLlmFallback": {
        "type": "boolean",
        "default": true,
        "description": "Fall back to cloud OpenAI if local LLM is unavailable"
      },
      "localLlmTimeoutMs": {
        "type": "number",
        "default": 180000,
        "description": "Hard timeout for local LLM requests (ms)"
      },
      "slowLogEnabled": {
        "type": "boolean",
        "default": false,
        "description": "If enabled, log slow operations (durations + metadata; never logs content)"
      },
      "slowLogThresholdMs": {
        "type": "number",
        "default": 30000,
        "description": "Threshold for slow operation logging (ms)"
      },
      "localLlmMaxContext": {
        "type": "number",
        "description": "Override the detected context window for local LLM. Set to 32768 if your LLM server defaults to 32K context despite the model supporting 128K."
      }
    }
  },
  "uiHints": {
    "openaiApiKey": {
      "label": "OpenAI API Key",
      "sensitive": true,
      "placeholder": "sk-...",
      "help": "API key for OpenAI (or use ${OPENAI_API_KEY})"
    },
    "model": {
      "label": "Extraction Model",
      "advanced": true,
      "placeholder": "gpt-5.2"
    },
    "reasoningEffort": {
      "label": "Reasoning Effort",
      "advanced": true
    },
    "triggerMode": {
      "label": "Trigger Mode",
      "advanced": true
    },
    "bufferMaxTurns": {
      "label": "Buffer Max Turns",
      "advanced": true,
      "placeholder": "5"
    },
    "bufferMaxMinutes": {
      "label": "Buffer Max Minutes",
      "advanced": true,
      "placeholder": "15"
    },
    "consolidateEveryN": {
      "label": "Consolidation Frequency",
      "advanced": true,
      "placeholder": "3"
    },
    "maxMemoryTokens": {
      "label": "Max Memory Tokens",
      "advanced": true,
      "placeholder": "2000"
    },
    "qmdEnabled": {
      "label": "Enable QMD",
      "help": "Enable QMD for memory search/indexing"
    },
    "qmdCollection": {
      "label": "QMD Collection",
      "advanced": true,
      "placeholder": "openclaw-engram"
    },
    "qmdMaxResults": {
      "label": "QMD Max Results",
      "advanced": true,
      "placeholder": "8"
    },
    "memoryDir": {
      "label": "Memory Directory",
      "advanced": true,
      "placeholder": "~/.openclaw/workspace/memory/local"
    },
    "debug": {
      "label": "Debug Mode",
      "advanced": true
    },
    "identityEnabled": {
      "label": "Identity Reflections",
      "help": "Append self-reflections to workspace IDENTITY.md after each extraction"
    },
    "injectQuestions": {
      "label": "Inject Questions",
      "help": "Include the most relevant open question in the system prompt"
    },
    "commitmentDecayDays": {
      "label": "Commitment Decay (days)",
      "advanced": true,
      "placeholder": "90"
    },
    "workspaceDir": {
      "label": "Workspace Directory",
      "advanced": true,
      "placeholder": "~/.openclaw/workspace"
    },
    "accessTrackingEnabled": {
      "label": "Access Tracking",
      "help": "Track which memories are accessed most frequently"
    },
    "accessTrackingBufferMaxSize": {
      "label": "Access Buffer Size",
      "advanced": true,
      "placeholder": "100"
    },
    "recencyWeight": {
      "label": "Recency Weight",
      "advanced": true,
      "help": "How much to boost recent memories in search (0-1)",
      "placeholder": "0.2"
    },
    "boostAccessCount": {
      "label": "Boost Frequent Access",
      "help": "Rank frequently accessed memories higher in search"
    },
    "negativeExamplesEnabled": {
      "label": "Negative Examples",
      "help": "Track retrieved-but-not-useful memories and apply a small ranking penalty (optional)"
    },
    "negativeExamplesPenaltyPerHit": {
      "label": "Negative Penalty / Hit",
      "advanced": true,
      "placeholder": "0.05"
    },
    "negativeExamplesPenaltyCap": {
      "label": "Negative Penalty Cap",
      "advanced": true,
      "placeholder": "0.25"
    },
    "chunkingEnabled": {
      "label": "Enable Chunking",
      "help": "Automatically split long memories into overlapping chunks for better retrieval"
    },
    "chunkingTargetTokens": {
      "label": "Chunk Target Tokens",
      "advanced": true,
      "placeholder": "200"
    },
    "chunkingMinTokens": {
      "label": "Chunk Min Tokens",
      "advanced": true,
      "placeholder": "150"
    },
    "chunkingOverlapSentences": {
      "label": "Chunk Overlap Sentences",
      "advanced": true,
      "placeholder": "2"
    },
    "contradictionDetectionEnabled": {
      "label": "Contradiction Detection",
      "help": "Detect and resolve conflicting memories using LLM verification"
    },
    "contradictionSimilarityThreshold": {
      "label": "Contradiction Similarity Threshold",
      "advanced": true,
      "placeholder": "0.7"
    },
    "contradictionMinConfidence": {
      "label": "Contradiction Min Confidence",
      "advanced": true,
      "placeholder": "0.9"
    },
    "contradictionAutoResolve": {
      "label": "Auto-Resolve Contradictions",
      "help": "Automatically supersede old memories when contradiction is confirmed"
    },
    "memoryLinkingEnabled": {
      "label": "Memory Linking",
      "help": "Build knowledge graph by linking related memories"
    },
    "threadingEnabled": {
      "label": "Conversation Threading",
      "help": "Group memories into conversation threads with auto-titles"
    },
    "threadingGapMinutes": {
      "label": "Thread Gap (minutes)",
      "advanced": true,
      "placeholder": "30"
    },
    "summarizationEnabled": {
      "label": "Memory Summarization",
      "help": "Compress old, low-importance memories into summaries"
    },
    "summarizationTriggerCount": {
      "label": "Summarization Trigger",
      "advanced": true,
      "placeholder": "1000"
    },
    "summarizationRecentToKeep": {
      "label": "Recent to Keep",
      "advanced": true,
      "placeholder": "300"
    },
    "summarizationImportanceThreshold": {
      "label": "Importance Threshold",
      "advanced": true,
      "placeholder": "0.3"
    },
    "topicExtractionEnabled": {
      "label": "Topic Extraction",
      "help": "Extract key topics from memory corpus"
    },
    "topicExtractionTopN": {
      "label": "Top N Topics",
      "advanced": true,
      "placeholder": "50"
    },
    "transcriptEnabled": {
      "label": "Enable Transcript Archive",
      "help": "Archive conversation transcripts for context preservation"
    },
    "transcriptRetentionDays": {
      "label": "Transcript Retention (days)",
      "advanced": true,
      "placeholder": "7"
    },
    "transcriptSkipChannelTypes": {
      "label": "Skip Channel Types",
      "advanced": true,
      "help": "Channel types to exclude from transcript logging (default: cron)"
    },
    "transcriptRecallHours": {
      "label": "Transcript Recall (hours)",
      "advanced": true,
      "placeholder": "12"
    },
    "maxTranscriptTurns": {
      "label": "Max Transcript Turns",
      "advanced": true,
      "placeholder": "50"
    },
    "maxTranscriptTokens": {
      "label": "Max Transcript Tokens",
      "advanced": true,
      "placeholder": "1000"
    },
    "checkpointEnabled": {
      "label": "Enable Checkpoints",
      "help": "Capture conversation checkpoints for resuming context"
    },
    "checkpointTurns": {
      "label": "Checkpoint Turn Interval",
      "advanced": true,
      "placeholder": "15"
    },
    "hourlySummariesEnabled": {
      "label": "Enable Hourly Summaries",
      "help": "Generate hourly summaries of conversation activity"
    },
    "summaryRecallHours": {
      "label": "Summary Recall (hours)",
      "advanced": true,
      "placeholder": "24"
    },
    "maxSummaryCount": {
      "label": "Max Summary Count",
      "advanced": true,
      "placeholder": "6"
    },
    "summaryModel": {
      "label": "Summary Model",
      "advanced": true,
      "placeholder": "(same as extraction model)"
    },
    "localLlmEnabled": {
      "label": "Enable Local LLM",
      "help": "Use local LLM (LM Studio, Ollama, etc.) for extraction and summaries. Falls back to OpenAI if unavailable."
    },
    "localLlmUrl": {
      "label": "Local LLM URL",
      "advanced": true,
      "placeholder": "http://localhost:1234/v1",
      "help": "OpenAI-compatible endpoint URL for local LLM"
    },
    "localLlmModel": {
      "label": "Local LLM Model",
      "advanced": true,
      "placeholder": "local-model",
      "help": "Model identifier for local LLM requests"
    },
    "localLlmFallback": {
      "label": "Local LLM Fallback",
      "advanced": true,
      "help": "Fall back to cloud OpenAI if local LLM fails or is unavailable"
    },
    "localLlmMaxContext": {
      "label": "Local LLM Max Context",
      "advanced": true,
      "placeholder": "(auto-detected from model)",
      "help": "Override context window if your LLM server uses smaller default (e.g., 32768 for LM Studio default)"
    }
  }
}
